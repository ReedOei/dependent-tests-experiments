org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r12 = r0.<org.apache.ambari.server.upgrade.UpgradeCatalog240: com.google.inject.Injector injector> >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r13 = interfaceinvoke $r12.<com.google.inject.Injector: java.lang.Object getInstance(java.lang.Class)>(class "org/apache/ambari/server/controller/AmbariManagementController")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r13 = interfaceinvoke $r12.<com.google.inject.Injector: java.lang.Object getInstance(java.lang.Class)>(class "org/apache/ambari/server/controller/AmbariManagementController") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r1 = (org.apache.ambari.server.controller.AmbariManagementController) $r13
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r1 = (org.apache.ambari.server.controller.AmbariManagementController) $r13 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r2 = interfaceinvoke r1.<org.apache.ambari.server.controller.AmbariManagementController: org.apache.ambari.server.state.Clusters getClusters()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r2 = interfaceinvoke r1.<org.apache.ambari.server.controller.AmbariManagementController: org.apache.ambari.server.state.Clusters getClusters()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r3 = virtualinvoke r0.<org.apache.ambari.server.upgrade.UpgradeCatalog240: java.util.Map getCheckedClusterMap(org.apache.ambari.server.state.Clusters)>(r2)
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r3 = virtualinvoke r0.<org.apache.ambari.server.upgrade.UpgradeCatalog240: java.util.Map getCheckedClusterMap(org.apache.ambari.server.state.Clusters)>(r2) >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r14 = interfaceinvoke r3.<java.util.Map: java.util.Collection values()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r14 = interfaceinvoke r3.<java.util.Map: java.util.Collection values()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r4 = interfaceinvoke $r14.<java.util.Collection: java.util.Iterator iterator()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r4 = interfaceinvoke $r14.<java.util.Collection: java.util.Iterator iterator()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z0 == 0
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z0 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r15 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z0 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : return
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r15 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r5 = (org.apache.ambari.server.state.Cluster) $r15
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r5 = (org.apache.ambari.server.state.Cluster) $r15 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r6 = interfaceinvoke r5.<org.apache.ambari.server.state.Cluster: org.apache.ambari.server.state.Config getDesiredConfigByType(java.lang.String)>("spark-defaults")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r6 = interfaceinvoke r5.<org.apache.ambari.server.state.Cluster: org.apache.ambari.server.state.Config getDesiredConfigByType(java.lang.String)>("spark-defaults") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if r6 == null
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if r6 == null >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r16 = new java.util.HashMap
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if r6 == null >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r25 = interfaceinvoke r5.<org.apache.ambari.server.state.Cluster: org.apache.ambari.server.state.Config getDesiredConfigByType(java.lang.String)>("spark-javaopts-properties")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r25 = interfaceinvoke r5.<org.apache.ambari.server.state.Cluster: org.apache.ambari.server.state.Config getDesiredConfigByType(java.lang.String)>("spark-javaopts-properties") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if r25 == null
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if r25 == null >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r26 = new java.util.HashMap
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if r25 == null >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()] >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r26 = new java.util.HashMap >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : specialinvoke $r26.<java.util.HashMap: void <init>()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : specialinvoke $r26.<java.util.HashMap: void <init>()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r27 = $r26
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r27 = $r26 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r28 = interfaceinvoke r25.<org.apache.ambari.server.state.Config: java.util.Map getProperties()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r28 = interfaceinvoke r25.<org.apache.ambari.server.state.Config: java.util.Map getProperties()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z5 = interfaceinvoke r28.<java.util.Map: boolean containsKey(java.lang.Object)>("content")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z5 = interfaceinvoke r28.<java.util.Map: boolean containsKey(java.lang.Object)>("content") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z5 == 0
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z5 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r29 = interfaceinvoke r28.<java.util.Map: java.lang.Object get(java.lang.Object)>("content")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z5 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r29 = interfaceinvoke r28.<java.util.Map: java.lang.Object get(java.lang.Object)>("content") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r30 = (java.lang.String) $r29
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r30 = (java.lang.String) $r29 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z6 = virtualinvoke r30.<java.lang.String: boolean contains(java.lang.CharSequence)>("{{hdp_full_version}}")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z6 = virtualinvoke r30.<java.lang.String: boolean contains(java.lang.CharSequence)>("{{hdp_full_version}}") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z6 == 0
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z6 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r31 = <org.apache.ambari.server.upgrade.UpgradeCatalog240: org.slf4j.Logger LOG>
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z6 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r31 = <org.apache.ambari.server.upgrade.UpgradeCatalog240: org.slf4j.Logger LOG> >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke $r31.<org.slf4j.Logger: void info(java.lang.String)>("Updating property content in spark-javaopts-properties")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke $r31.<org.slf4j.Logger: void info(java.lang.String)>("Updating property content in spark-javaopts-properties") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r11 = virtualinvoke r30.<java.lang.String: java.lang.String replace(java.lang.CharSequence,java.lang.CharSequence)>("{{hdp_full_version}}", "{{full_stack_version}}")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r11 = virtualinvoke r30.<java.lang.String: java.lang.String replace(java.lang.CharSequence,java.lang.CharSequence)>("{{hdp_full_version}}", "{{full_stack_version}}") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke r27.<java.util.Map: java.lang.Object put(java.lang.Object,java.lang.Object)>("content", r11)
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke r27.<java.util.Map: java.lang.Object put(java.lang.Object,java.lang.Object)>("content", r11) >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : virtualinvoke r0.<org.apache.ambari.server.upgrade.UpgradeCatalog240: void updateConfigurationPropertiesForCluster(org.apache.ambari.server.state.Cluster,java.lang.String,java.util.Map,java.util.Set,boolean,boolean)>(r5, "spark-javaopts-properties", r27, null, 1, 0)
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : virtualinvoke r0.<org.apache.ambari.server.upgrade.UpgradeCatalog240: void updateConfigurationPropertiesForCluster(org.apache.ambari.server.state.Cluster,java.lang.String,java.util.Map,java.util.Set,boolean,boolean)>(r5, "spark-javaopts-properties", r27, null, 1, 0) >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r16 = new java.util.HashMap >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : specialinvoke $r16.<java.util.HashMap: void <init>()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : specialinvoke $r16.<java.util.HashMap: void <init>()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r7 = $r16
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r7 = $r16 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r8 = interfaceinvoke r6.<org.apache.ambari.server.state.Config: java.util.Map getProperties()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r8 = interfaceinvoke r6.<org.apache.ambari.server.state.Config: java.util.Map getProperties()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z1 = interfaceinvoke r8.<java.util.Map: boolean containsKey(java.lang.Object)>("spark.driver.extraJavaOptions")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z1 = interfaceinvoke r8.<java.util.Map: boolean containsKey(java.lang.Object)>("spark.driver.extraJavaOptions") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z1 == 0
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z1 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r17 = <org.apache.ambari.server.upgrade.UpgradeCatalog240: org.slf4j.Logger LOG>
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z1 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z3 = interfaceinvoke r8.<java.util.Map: boolean containsKey(java.lang.Object)>("spark.yarn.am.extraJavaOptions")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z3 = interfaceinvoke r8.<java.util.Map: boolean containsKey(java.lang.Object)>("spark.yarn.am.extraJavaOptions") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z3 == 0
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z3 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r20 = <org.apache.ambari.server.upgrade.UpgradeCatalog240: org.slf4j.Logger LOG>
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z3 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $i0 = interfaceinvoke r7.<java.util.Map: int size()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $i0 = interfaceinvoke r7.<java.util.Map: int size()>() >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $i0 == 0
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $i0 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : virtualinvoke r0.<org.apache.ambari.server.upgrade.UpgradeCatalog240: void updateConfigurationPropertiesForCluster(org.apache.ambari.server.state.Cluster,java.lang.String,java.util.Map,java.util.Set,boolean,boolean)>(r5, "spark-defaults", r7, null, 1, 0)
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $i0 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r25 = interfaceinvoke r5.<org.apache.ambari.server.state.Cluster: org.apache.ambari.server.state.Config getDesiredConfigByType(java.lang.String)>("spark-javaopts-properties")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : virtualinvoke r0.<org.apache.ambari.server.upgrade.UpgradeCatalog240: void updateConfigurationPropertiesForCluster(org.apache.ambari.server.state.Cluster,java.lang.String,java.util.Map,java.util.Set,boolean,boolean)>(r5, "spark-defaults", r7, null, 1, 0) >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r25 = interfaceinvoke r5.<org.apache.ambari.server.state.Cluster: org.apache.ambari.server.state.Config getDesiredConfigByType(java.lang.String)>("spark-javaopts-properties")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r20 = <org.apache.ambari.server.upgrade.UpgradeCatalog240: org.slf4j.Logger LOG> >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke $r20.<org.slf4j.Logger: void info(java.lang.String)>("Updating property spark.yarn.am.extraJavaOptions in spark-defaults")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke $r20.<org.slf4j.Logger: void info(java.lang.String)>("Updating property spark.yarn.am.extraJavaOptions in spark-defaults") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r21 = interfaceinvoke r8.<java.util.Map: java.lang.Object get(java.lang.Object)>("spark.yarn.am.extraJavaOptions")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r21 = interfaceinvoke r8.<java.util.Map: java.lang.Object get(java.lang.Object)>("spark.yarn.am.extraJavaOptions") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r22 = (java.lang.String) $r21
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r22 = (java.lang.String) $r21 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z4 = virtualinvoke r22.<java.lang.String: boolean contains(java.lang.CharSequence)>("{{hdp_full_version}}")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z4 = virtualinvoke r22.<java.lang.String: boolean contains(java.lang.CharSequence)>("{{hdp_full_version}}") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z4 == 0
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z4 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r23 = virtualinvoke r22.<java.lang.String: java.lang.String replace(java.lang.CharSequence,java.lang.CharSequence)>("{{hdp_full_version}}", "{{full_stack_version}}")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z4 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $i0 = interfaceinvoke r7.<java.util.Map: int size()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r23 = virtualinvoke r22.<java.lang.String: java.lang.String replace(java.lang.CharSequence,java.lang.CharSequence)>("{{hdp_full_version}}", "{{full_stack_version}}") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke r7.<java.util.Map: java.lang.Object put(java.lang.Object,java.lang.Object)>("spark.yarn.am.extraJavaOptions", r23)
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke r7.<java.util.Map: java.lang.Object put(java.lang.Object,java.lang.Object)>("spark.yarn.am.extraJavaOptions", r23) >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $i0 = interfaceinvoke r7.<java.util.Map: int size()>()
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r17 = <org.apache.ambari.server.upgrade.UpgradeCatalog240: org.slf4j.Logger LOG> >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke $r17.<org.slf4j.Logger: void info(java.lang.String)>("Updating property spark.driver.extraJavaOptions in spark-defaults")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke $r17.<org.slf4j.Logger: void info(java.lang.String)>("Updating property spark.driver.extraJavaOptions in spark-defaults") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r18 = interfaceinvoke r8.<java.util.Map: java.lang.Object get(java.lang.Object)>("spark.driver.extraJavaOptions")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $r18 = interfaceinvoke r8.<java.util.Map: java.lang.Object get(java.lang.Object)>("spark.driver.extraJavaOptions") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r9 = (java.lang.String) $r18
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r9 = (java.lang.String) $r18 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z2 = virtualinvoke r9.<java.lang.String: boolean contains(java.lang.CharSequence)>("{{hdp_full_version}}")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z2 = virtualinvoke r9.<java.lang.String: boolean contains(java.lang.CharSequence)>("{{hdp_full_version}}") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z2 == 0
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z2 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r10 = virtualinvoke r9.<java.lang.String: java.lang.String replace(java.lang.CharSequence,java.lang.CharSequence)>("{{hdp_full_version}}", "{{full_stack_version}}")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : if $z2 == 0 >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z3 = interfaceinvoke r8.<java.util.Map: boolean containsKey(java.lang.Object)>("spark.yarn.am.extraJavaOptions")
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : r10 = virtualinvoke r9.<java.lang.String: java.lang.String replace(java.lang.CharSequence,java.lang.CharSequence)>("{{hdp_full_version}}", "{{full_stack_version}}") >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke r7.<java.util.Map: java.lang.Object put(java.lang.Object,java.lang.Object)>("spark.driver.extraJavaOptions", r10)
org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : interfaceinvoke r7.<java.util.Map: java.lang.Object put(java.lang.Object,java.lang.Object)>("spark.driver.extraJavaOptions", r10) >>>>>>>> org.apache.ambari.server.upgrade.UpgradeCatalog240.updateSparkConfigs : $z3 = interfaceinvoke r8.<java.util.Map: boolean containsKey(java.lang.Object)>("spark.yarn.am.extraJavaOptions")
